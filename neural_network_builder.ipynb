{
 "cells": [
  {
   "source": [
    "Neural network designer\n",
    "========================"
   ],
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extensies en dependencies laden\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training-dataset inlezen\n",
    "------------------------"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_variables(filename: str) -> list:\n",
    "    \"\"\"A function which reads a file and returns the\n",
    "       contents of the file as two seperate lists.\n",
    "    \n",
    "    Input = filename to read the contents from(str).\n",
    "    Output = -list of all values in the file (list).\n",
    "             -list of all labels in the file (list).\n",
    "    \"\"\"\n",
    "    values = []\n",
    "    labels = []\n",
    "    with open(filename, \"r\", encoding=\"UTF-8\") as content:\n",
    "        # Search the header and index the columns.\n",
    "        line = content.readline().strip()\n",
    "        while line == \"\" or not line.startswith(\"#\"):\n",
    "            content.readline()\n",
    "        header = line.replace(\"#\", \"\").split(\"\\t\")\n",
    "        col_values = header.index(\"Value\")\n",
    "        col_labels = header.index(\"Label\")\n",
    "        # Put the rest of the file in the corresponding lists.\n",
    "        for line in content:\n",
    "            splitted_line = line.strip().split(\"\\t\")\n",
    "            values.append(str(splitted_line[col_values]))\n",
    "            labels.append(int(splitted_line[col_labels]))\n",
    "    return values, labels"
   ]
  },
  {
   "source": [
    "file_training = \"dataset.txt\"\n",
    "values_training, labels_training = read_variables(file_training)\n",
    "\n",
    "print(f\"Count of values (training): {len(values_training)}\")\n",
    "print(f\"Count of labels (training): {len(labels_training)}\", end=\"\\n\\n\")\n",
    "\n",
    "for value, label in zip(values_training[:5], labels_training[:5]):\n",
    "    print(f\"{value} {label}\")"
   ],
   "cell_type": "code",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "Pre-processing van dataset\n",
    "--------------------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheek opbouwen van alle unieke karakters.\n",
    "tokenizer = Tokenizer(char_level=True, lower=False)\n",
    "tokenizer.fit_on_texts(values_training)\n",
    "\n",
    "print(f\"Unieke karakters: {sorted(tokenizer.word_counts.keys())}\", end=\"\\n\\n\")\n",
    "print(f\"Index: {tokenizer.word_index}\", end=\"\\n\\n\")\n",
    "print(f\"Aantal: {len(tokenizer.word_index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings omzetten naar sequences.\n",
    "sequences = tokenizer.texts_to_sequences(values_training)\n",
    "\n",
    "for value, sequence in zip(values_training[:5], sequences[:5]):\n",
    "    print(f\"{value.ljust(12, ' ')}: {str(sequence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequences omzetten naar een binaire matrix.\n",
    "values_binary_matrix = tokenizer.sequences_to_matrix(sequences, mode=\"binary\")\n",
    "\n",
    "print(values_binary_matrix[:3], end=\"\\n\\n\")\n",
    "print(f\"Vorm van matrix: {values_binary_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels naar een array omzetten.\n",
    "labels_array = np.array(labels_training)\n",
    "print(labels_array)"
   ]
  },
  {
   "source": [
    "Model opbouwen\n",
    "--------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model opbouwen en een samenvatting geven.\n",
    "model = Sequential([\n",
    "    Dense(units=60, activation=\"relu\", input_shape=values_binary_matrix[0].shape),\n",
    "    Dense(units=50, activation=\"relu\"),\n",
    "    Dense(units=50, activation=\"relu\"),\n",
    "    Dense(units=40, activation=\"relu\"),\n",
    "    Dense(units=20, activation=\"relu\"),\n",
    "    Dense(units=2, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compileren.\n",
    "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "source": [
    "Model trainen\n",
    "-------------"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=values_binary_matrix,\n",
    "    y=labels_array,\n",
    "    shuffle=True,\n",
    "    validation_split=0.2,\n",
    "    batch_size=10,\n",
    "    epochs=2\n",
    ")"
   ]
  },
  {
   "source": [
    "Demo: voorspellingen doen\n",
    "========================="
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_values = (\"Rhodopsin\", \"VS\", \"RHO\", \"rho1\", \"brandweerauto\", \"Covid-19\", \"kattenpoot\", \"envelope\", \"rhodopsinterklaas\")\n",
    "longest_example = len(sorted(example_values, key=lambda value: len(value), reverse=True)[0])\n",
    "\n",
    "# Waardes omzetten naar sequences.\n",
    "example_sequences = tokenizer.texts_to_sequences(example_values)\n",
    "\n",
    "# Sequences omzetten naar matrixes.\n",
    "example_matrix = tokenizer.sequences_to_matrix(example_sequences)\n",
    "\n",
    "# Voorspellingen doen op matrixes.\n",
    "example_predictions = model.predict(example_matrix)\n",
    "example_rounded_predictions = np.argmax(example_predictions, axis=-1)\n",
    "\n",
    "print(\"Voorspellingen, 0=woord, 1=symbool:\")\n",
    "for value, prediction, percentage in zip(example_values, example_rounded_predictions, example_predictions):\n",
    "    print(f\"{value.ljust(longest_example, ' ')} : {prediction} ({round(percentage[prediction]*100)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pythonjvsc74a57bd0f6aa2b9f5ba1f8420e941b312725c59e8dca41a3f51556a6ceaac9b5421b6a14",
   "display_name": "Python 3.8.9  ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "f6aa2b9f5ba1f8420e941b312725c59e8dca41a3f51556a6ceaac9b5421b6a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}